{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33b0dad9",
   "metadata": {},
   "source": [
    "## This file merges cleaned UC, Texas, Michigan and Illinois salary datasets with unique person IDs together and standardize field / departments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a27e593e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "os.chdir('/Users/apple/Desktop/research_fellow_documents/merge_sum_salary/')\n",
    "\n",
    "uc = pd.read_csv('salary_data/uc_salary.csv')\n",
    "texas = pd.read_csv('salary_data/texas_salary.csv')\n",
    "michigan = pd.read_csv('salary_data/michigan_salary.csv')\n",
    "illinois = pd.read_csv('salary_data/illinois_salary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d02c234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "664921"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(illinois) + len(texas) +len(michigan) + len(uc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01fe05ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "texas = texas.drop(columns=['rid'])\n",
    "michigan = michigan.drop(columns=['rid','gross_notnull','title_prof'])\n",
    "illinois = illinois.drop(columns=['rid'])\n",
    "uc = uc.drop(columns=['yrid'])\n",
    "\n",
    "#standardize names\n",
    "illinois['name'] = illinois['name'].str.upper()\n",
    "texas['name'] = texas['name'].str.upper()\n",
    "\n",
    "uc['name'] = uc['first_name'] + ' '+ uc['last_name']\n",
    "michigan['name'] = michigan['first_name'] + ' '+ michigan['last_name']\n",
    "\n",
    "#standardize ranks\n",
    "texas['rank'] = np.where(texas['title'].str.contains('Assistant|ASST', na = False, case = False, regex=True),'Assistant', texas['rank'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1456c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "uc['univ_sys'] = 'UC'\n",
    "michigan['univ_sys'] = 'Michigan'\n",
    "illinois['univ_sys'] = 'Illinois'\n",
    "texas['univ_sys'] = 'Texas'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d5b498",
   "metadata": {},
   "source": [
    "### Make prof_type column in UC data - recoding cto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6a119b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "uc_maps = {'Professorial-Tenure': 'Professorial', \n",
    " 'Health Sciences Clinical Professor': 'Clinical',\n",
    " 'Professorial-Non-Tenure':'Professorial',\n",
    " 'Adjunct Professor':'Adjunct',\n",
    " 'Professor in Residence':'Professorial',\n",
    " 'Professor of Clinical':'Clinical',\n",
    " 'Visiting Professor':'Visiting',\n",
    " 'Professorial-Recall':'Professorial',\n",
    " 'Clinical Professor - Volunteer':'Clinical',\n",
    " 'Professorial-Emeritus':'Emeritus',\n",
    " 'Acting Professor-Senate':'Professorial', \n",
    " 'Acting Professor-Non-Senate': 'Professorial', \n",
    " 'Clin Prof-Dentistry-50%+/Tenure': 'Clinical',\n",
    " 'Miscellaneous Titles-Single Titles':'Professorial', \n",
    " 'Other Research':'Professorial'}\n",
    "uc['prof_type'] = uc['cto'].map(uc_maps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21c0d48",
   "metadata": {},
   "source": [
    "Create unique person IDs for the merged dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a2a49ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Texas       101505\n",
       "UC           37918\n",
       "Illinois     23359\n",
       "Michigan     12607\n",
       "Name: univ_sys, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([uc, michigan, texas, illinois], ignore_index = True)\n",
    "df.uid = df.groupby(['uid','univ_sys']).ngroup()\n",
    "\n",
    "df.drop_duplicates(['uid'])['univ_sys'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e8ef0c",
   "metadata": {},
   "source": [
    "### Make department to field mapping consistent across universities\n",
    "\n",
    "1. Hand check department - field matching using dept2field.xlsx. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "79f1f9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dept2field = df.groupby(['department','field','cip_code'])['uid'].count().reset_index()\n",
    "dept2field.to_excel('cip_check/dept2field.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc03d01",
   "metadata": {},
   "source": [
    "2. create two level field matches: field_macro using 2 digits cip code and field_micro using 4 digits cip code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc260485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182\n"
     ]
    }
   ],
   "source": [
    "dm = pd.read_excel('cip_check/dept2field_check.xlsx')\n",
    "dm['field_new'] = np.where(dm['field_check'].notnull(), dm['field_check'], dm['field'])\n",
    "\n",
    "codes = dm[['field','cip_code']].drop_duplicates(['field'])\n",
    "codes_dict = dict(zip(codes.field, codes.cip_code))\n",
    "\n",
    "dm['cip_code_new'] = dm['field_new'].map(codes_dict)\n",
    "dm['cip_code_new'] = dm['cip_code_new'].astype('str')\n",
    "dm['cip_code_macro'] = dm['cip_code_new'].str.split('.').str[0]\n",
    "print(len(dm[dm['cip_code_macro'].str.len() == 1]))\n",
    "dm['cip_code_new'] = np.where(dm['cip_code_macro'].str.len() == 1, '0'+ dm['cip_code_new'], dm['cip_code_new'])\n",
    "dm['cip_code_macro'] = dm['cip_code_new'].str.split('.').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07e22566",
   "metadata": {},
   "outputs": [],
   "source": [
    "cip = pd.read_csv('cip_check/CIPCode2020.csv')\n",
    "\n",
    "cip['CIPCode'] = cip['CIPCode'].str.replace('=|\"|','', regex=True)\n",
    "cip_zip = cip[['CIPCode','CIPTitle']]\n",
    "dc = dict(zip(cip_zip.CIPCode, cip_zip.CIPTitle))\n",
    "dm['field_macro'] = dm['cip_code_macro'].map(dc)\n",
    "dm['cip_code_micro'] = dm['cip_code_new'].str[0:5]\n",
    "dm['field_micro'] = dm['cip_code_micro'].map(dc)\n",
    "dm.rename(columns = {'cip_code_new':'cip_code_raw'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b105e21b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "664921\n",
      "664921\n"
     ]
    }
   ],
   "source": [
    "keep = ['department','cip_code_macro','cip_code_micro','cip_code_raw','field_macro','field_micro']\n",
    "\n",
    "dm2 = dm[keep]\n",
    "dm2 = dm2.drop_duplicates()\n",
    "dm2 = dm2.drop_duplicates(['department'])\n",
    "\n",
    "print(len(df))\n",
    "df2 = df.drop(columns = ['cip_code']).merge(dm2, on = ['department'], how='left')\n",
    "print(len(df2))\n",
    "df2 = df2[['university', 'uid', 'yr', 'first_name', 'last_name', 'department', 'field', 'field_macro', 'field_micro','title',\n",
    "       'rank', 'gross_pay','regular_pay', 'overtime_pay', 'other_pay',\n",
    "       'suspicious', 'gross_pay_sum', 'regular_pay_sum', 'name', 'univ_sys',\n",
    "       'prof_type', 'fte', 'pay_term', 'gen_fund', 'college', 'division',\n",
    "       'gen_fund_sum', 'college_code', 'department_code', 'emp_no',\n",
    "       'multiple_jobs', 'fte_total', 'tenure', 'emplclass', 'cip_code_macro',\n",
    "       'cip_code_micro', 'cip_code_raw', 'title_code', 'series', 'cto', 'cto_code']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78cdeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardize names across universities\n",
    "\n",
    "df2['first_name'] = df2['first_name'].str.upper()\n",
    "df2['last_name'] = df2['last_name'].str.upper()\n",
    "dft = df2[df2['univ_sys'] == 'Texas']\n",
    "dfi = df2[df2['univ_sys'] == 'Illinois']\n",
    "dfc = df2[df2['univ_sys'] == 'UC']\n",
    "dfm = df2[df2['univ_sys'] == 'Michigan']\n",
    "dfi['first_name'] = dfi['name'].str.split(', ').str[-1].str.split(' ').str[0]\n",
    "dfi['last_name'] = dfi['name'].str.split(', ').str[0]\n",
    "#dfi['fn2'] = dfi['name'].str.split(', ').str[-1].str.split(' ').str[-1]\n",
    "df2 = pd.concat([dft, dfi, dfc, dfm], ignore_index = True).sort_values(['univ_sys','university','uid','last_name','first_name','yr'])\n",
    "df2.to_csv('salary_data/salary_all.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
